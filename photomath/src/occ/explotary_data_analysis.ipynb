{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset\n",
    "https://www.kaggle.com/clarencezhao/handwritten-math-symbol-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/anton/Downloads/archive/train\"\n",
    "symbols_list = ['zero','one','two','three','four','five','six','seven','eight','nine','minus','plus','equal','div','decimal','times']\n",
    "train_image = []\n",
    "train_label = []\n",
    "for symbols_dir in os.listdir(dataset_path):\n",
    "    if symbols_dir.split()[0] in symbols_list:\n",
    "        for image in os.listdir(dataset_path + \"/\" + symbols_dir):\n",
    "            train_label.append(symbols_dir.split()[0])\n",
    "            train_image.append(dataset_path + \"/\" + symbols_dir + \"/\" + image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"/home/anton/Downloads/archive/eval\"\n",
    "test_image = []\n",
    "test_label = []\n",
    "\n",
    "for symbols_dir in os.listdir(eval_path):\n",
    "    if symbols_dir.split()[0] in symbols_list:\n",
    "        for image in os.listdir(eval_path + \"/\" + symbols_dir):\n",
    "            test_label.append(symbols_dir.split()[0])\n",
    "            test_image.append(eval_path + \"/\" + symbols_dir + \"/\" + image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of train_image : \" , len(train_image) , \" , length of labels list : \" ,len(train_label))\n",
    "print(\"Length of test_image : \" , len(test_image) , \" , length of labels list : \" ,len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_test = list(set(test_label))\n",
    "unique_train = list(set(train_label))\n",
    "print(\"Length of test unique labels: \" , len(unique_test) , \" : \" , unique_test)\n",
    "print(\"Length of train unique labels: \" , len(unique_train) , \" : \" , unique_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASIAAAEICAYAAAD7ifnmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXJklEQVR4nO3dfXDdV53f8fdHD5b8VNuJ5Yf4IXYcEcaE3SSoWTPAToawjZdmcXaGMmFocSCpp4UusNBCDJ0mtP0DuluepixbbwJxs9lA1mEbkcKyJhvYkgYncpyE2IkTE8dYHj/IE0y8sWxZ8rd/3HPF1fWVLOvq6shXn9fMHf1+5/dwzrm++vj8zv3dK0UEZmY5NeRugJmZg8jMsnMQmVl2DiIzy85BZGbZOYjMLDsHkSHpx5Juy3DsdZK6x3Js2Xn+UdJl1Z6nwnlvkfTT8T6vnc1BVEckvSLpXbnbMdEiYlZEvJy7HTZ2DiIzy85BNAVImifpYUk9kn6VlpeW7bZK0hOSXpP0kKSLSo5fI+n/STom6RlJ142xHdMl3ZPasAv4p2XbL5H0YGrnXkkfK9nWKOmzkn4h6bik7ZKWpW0h6fK0fI+kP5P0g3TJ9pikRZK+kup9QdLVJee9veScuyT94Vj6ZtVxEE0NDcC3gEuB5UAv8D/K9vkg8GFgMdAPfA1A0hLg/wD/FbgI+PfAg5LayiuRtDyF1fJh2nEHsCo9bgDWlxzbAHwPeAZYAlwPfELSDWmXTwLvB94N/JPU1hPD1PM+4D8C84FTwOPAU2l9C/Clkn1/AbwDmAN8HvhLSYuHOa/VSkT4UScP4BXgXaPY7yrgVyXrPwa+ULK+GugDGoHPAPeWHf9DYH3JsbeNsn0vA2tL1jcA3Wn5d4Bflu2/EfhWWt4NrBvmvAFcnpbvAf6iZNsfAc+XrL8ZODZCG58u1gPcAvw097/rVHg0jUua2aQmaQbwZWAtMC8Vz5bUGBEDaX1/ySH7gGYKI4hLgX8h6Q9KtjcDj46hKZdUqKfoUuASScdKyhqB/5uWl1EYvYzG4ZLl3grrs4orkj5IYbS1IhXNotBvm0AOoqnhU8AVwO9ExCFJVwE7AJXss6xkeTlwGjhKITjujYh/PQ7tOJjq2VlST9F+YG9EtA9z7H4Kl3TPjUM7AJB0KfAXFC4DH4+IAUlPM/R5sQngOaL60yypteTRBMymMBI4liah76hw3L+UtDqNnv4zsCWNlv4S+ANJN6QJ49Z0/0/5ZPdoPABsTJPnSylcNhU9ARyX9Jk0qd0o6UpJxQntu4D/IqldBb8l6eIxtKHUTAqXdT0Akj4EXFnlOW0MHET15/sUQqf4uBP4CjCdwgjnZ8DfVjjuXgrzK4eAVuBjABGxH1gHfJbCL+x+4D9Q4bWTJqv/cYTJ6s9TuBzbC/xdqpNUzwBwI4X5q72prXdRmESGwgTzA+m414C7U5/GLCJ2Af+dwmT2YQrzR49Vc04bG6VJOTOzbDwiMrPsHERmll3NgkjSWkm7Je2RdHut6jGzC19N5ogkNQIvAr8HdANPAu9Pk4NmZkPU6j6ia4E9kT4RLenbFN55qRhE8+fPjxUrVtSoKWY2GWzfvv1oRJz10SCoXRAtYegdtN0UbuEfJGkDhVv8Wb58OV1dXTVqiplNBpL2Dbct22R1RGyKiI6I6GhrqxiSZjZF1CqIDjD0IwNLU5mZ2VlqFURPAu2SVkqaBtwMdNaoLjO7wNVkjigi+iX9OwpfF9EIfDMidp7jMDObomr26fuI+D6Fzz2ZmY3Id1abWXYOIjPLzkFkZtk5iMwsOweRmWXnIDKz7BxEZpadg8jMsnMQmVl2DiIzy85BZGbZOYjMLDsHkZll5yAys+wcRGaWnYPIzLJzEJlZdg4iM8vOQWRm2TmIzCw7B5GZZecgMrPsHERmlt2Yg0jSMkmPStolaaekj6fyiyRtlfRS+jlv/JprZvWomhFRP/CpiFgNrAE+Kmk1cDvwSES0A4+kdTOzYY05iCLiYEQ8lZaPA88DS4B1wOa022bgpirbaGZ1blzmiCStAK4GtgELI+Jg2nQIWDjMMRskdUnq6unpGY9mmNkFquogkjQLeBD4RES8VrotIgKISsdFxKaI6IiIjra2tmqbYWYXsKqCSFIzhRC6LyK+m4oPS1qcti8GjlTXRDOrd9W8aybgbuD5iPhSyaZOYH1aXg88NPbmmdlU0FTFsW8D/hXwc0lPp7LPAl8AHpB0K7APeF9VLTSzujfmIIqInwIaZvP1Yz2vmU09vrPazLJzEJlZdg4iM8vOQWRm2TmIzCw7B5GZZecgMrPsHERmlp2DyMyycxCZWXYOIjPLzkFkZtk5iMwsOweRmWXnIDKz7BxEZpadg8jMsnMQmVl2DiIzy85BZGbZOYjMLDsHkZll5yAys+yqDiJJjZJ2SHo4ra+UtE3SHknfkTSt+maaWT0bjxHRx4HnS9a/CHw5Ii4HfgXcOg51mFkdqyqIJC0F/jlwV1oX8E5gS9plM3BTNXWYWf2rdkT0FeDTwJm0fjFwLCL603o3sKTKOsyszo05iCTdCByJiO1jPH6DpC5JXT09PWNthpnVgWpGRG8D3iPpFeDbFC7JvgrMldSU9lkKHKh0cERsioiOiOhoa2urohlmdqEbcxBFxMaIWBoRK4Cbgb+PiA8AjwLvTbutBx6qupVmVtdqcR/RZ4BPStpDYc7o7hrUYWZ1pOncu5xbRPwY+HFafhm4djzOa2ZTg++sNrPsHERmlp2DyMyycxCZWXYOIjPLzkFkZtk5iMwsOweRmWXnIDKz7BxEZpadg8jMsnMQmVl2DiIzy85BZGbZOYjMLDsHkZll5yAys+wcRGaWnYPIzLJzEJlZdg4iM8vOQWRm2TmIzCw7B5GZZVdVEEmaK2mLpBckPS/prZIukrRV0kvp57zxaqyZ1adqR0RfBf42It4I/DbwPHA78EhEtAOPpHUzs2GNOYgkzQF+l/S37SOiLyKOAeuAzWm3zcBN1TXRzOpdNSOilUAP8C1JOyTdJWkmsDAiDqZ9DgELKx0saYOkLkldPT09VTTDzC501QRRE3AN8I2IuBp4nbLLsIgIICodHBGbIqIjIjra2tqqaIaZXeiqCaJuoDsitqX1LRSC6bCkxQDp55Hqmmhm9W7MQRQRh4D9kq5IRdcDu4BOYH0qWw88VFULzazuNVV5/B8B90maBrwMfIhCuD0g6VZgH/C+KuswszpXVRBFxNNAR4VN11dzXjObWnxntZll5yAys+wcRGaWnYPIzLJzEJlZdg4iM8vOQWRm2TmIzCw7B5GZZecgMrPsHERmlp2DyMyycxCZWXYOIjPLzkFkZtk5iMwsOweRmWXnIDKz7BxEZpadg8jMsnMQmVl2DiIzy85BZGbZVRVEkv5Y0k5Jz0m6X1KrpJWStknaI+k76Y8vmpkNa8xBJGkJ8DGgIyKuBBqBm4EvAl+OiMuBXwG3jkdDbeJFxJDHaPaptP9I28q3j/YYqy/VXpo1AdMlNQEzgIPAO4Etaftm4KYq67BJqhgQZ86cGVJWabma81v9G3MQRcQB4E+BX1IIoF8D24FjEdGfdusGllQ6XtIGSV2Sunp6esbaDMukUkCMJTRGMzoq39ejpPpTzaXZPGAdsBK4BJgJrB3t8RGxKSI6IqKjra1trM2wTCKCgYEBABoaGgZHRZIG9yldPh8DAwMMDAwgafAcDp/61lTFse8C9kZED4Ck7wJvA+ZKakqjoqXAgeqbaTmUB0kxCIoB0dDQMLhPaWiUH1spkEaac2poaBiyXlqn1adq5oh+CayRNEOFV8j1wC7gUeC9aZ/1wEPVNdFyG27SuDQwSkculY4pLx9JacgV56AcQvWtmjmibRQmpZ8Cfp7OtQn4DPBJSXuAi4G7x6GdNgkUA6JoIi6XKo2Ezpw5M2SC3C581VyaERF3AHeUFb8MXFvNeW1yKA+Y48ePc/z4cfbt28fAwACNjY1cfvnlzJ07l+bm5iHHnc/lWKnykVV5+JXuY/WjqiCyqeXQoUPs2bOHBx98kJMnT9La2sptt93GlVdeSVNT0+DopTjRXGn0BJw1CV1UKWAqBZODqP44iOycjh49SmdnJ4899hhPP/00hw8f5syZMzQ2NnLy5EkuvfRSFi1axOnTp+nr66Ovr4/Tp0/T29vL6dOnB4OpeEnV19dHRNDU1ERrayutra20t7ezcuVK3vKWtzB79myamoa+NEcbXHZhchDZiE6cOMGRI0d4/PHHeeKJJ9i1a9eQ0cmOHTs4cOAAixYtoq+vj1OnTg2G0YkTJ+jr6xsSRAMDA5w6dYqIoLm5menTpzN9+nSOHj3Kq6++yvTp02lvb2fOnDm0tLSMeD+Rg6h+OIhsRE899RRPPvkk9957L/39/Wdt3717Ny+++OLgejFwikaaF2poaBjcvmPHDqZPn86cOXO48847WbNmDW984xsHz1G8zPOlWX1yENmIXnjhBXbu3El/f/9Zb6NX+45Z8YZIKLwTVrxJ8nvf+x7d3d185CMfYebMmbS0tAyp02FUf/w1IDasiOCll15i9+7dQ+4DqpX+/n5ef/11tm7dSmdnJ0ePHuXkyZNnhZ/VHweRjejw4cMcPHjwrEniWo1IJNHb28uRI0f40Y9+xN69e4HfjJjK38q3+uB/VRtRS0sLLS0tFT/uUSsRMTg66uvrA4b/uInVBweRjWjx4sUsWbLkrHuCRlIcMZ1r5FRpe2nANDc309jYeNb5fGd1/XEQ2bAksWbNGt7+9rcPKS/9sGtRMTBg5C9UG81k98yZM1m4cCHveMc7WL58+ZBzFSfMfYlWX/yumY1o1apVvPbaayxYsIDjx49z8uTJihPXxdHKSKOlc80rSaKpqYlFixaxYsUKLrvsMmbNmnXe57ELj4PIRrRq1Souvvhivv71r9PZ2clPfvIT9u/fP3hndXESub+/v2IYlY+SRlIcCd15551ce+21zJ49e/C7jjwCqm8OIhuRJGbMmMHq1avp7+9n1apV7N27l97eXnp7ewcnlIsf5RgYGBi8m7qvr2/IfE4xjIo3RjY0NNDc3ExzczMLFixgyZIlrF69mje/+c0sWLDgrMs9j4Tql4PIRhQRTJs2jTe84Q20t7czMDDAyy+/zLFjxzh8+DA9PT28/vrrHD9+nFOnTnHy5ElOnDjBqVOnBsv6+/sHRzYDAwP09vYCMG3aNGbMmMGsWbO46qqreNOb3sR1111Hc3PzWSOg4T40a/XBQWQjKv/ys6amJpYtW8Yll1zCFVdcwenTpwcDpvgon1wuKp/AlkRjYyMNDQ3MmDGD1tZWGhsbB/ctXub5/qH65yCy89ba2gpUvren+K5W6eN87vc517cxloZTpTbYhclBZOet/CtcS7+3ujiiGatKX4J2vmFmFx6Pd23UKn1J2bkMFyDDzfOc7/5WHzwisvM23CfgRxMsI4VJ6V/sGO0xVh8cRHbeajVx7FHP1OUgsmGN9B3S1ZyjmvNZffIckZll5yAys+zOGUSSvinpiKTnSsoukrRV0kvp57xULklfk7RH0rOSrqll482sPoxmRHQPsLas7HbgkYhoBx5J6wC/D7SnxwbgG+PTTDOrZ+cMooj4B+DVsuJ1wOa0vBm4qaT8f0XBz4C5khaPU1vNrE6NdY5oYUQcTMuHgIVpeQmwv2S/7lR2FkkbJHVJ6urp6RljM8ysHlQ9WR2FO9bO+/77iNgUER0R0dHW1lZtM8zsAjbWIDpcvORKP4+k8gPAspL9lqYyM7NhjTWIOoH1aXk98FBJ+QfTu2drgF+XXMKZmVV0zjurJd0PXAfMl9QN3AF8AXhA0q3APuB9affvA+8G9gAngA/VoM1mVmfOGUQR8f5hNl1fYd8APlpto8xsavGd1WaWnYPIzLJzEJlZdg4iM8vOQWRm2TmIzCw7B5GZZecgMrPsHERmlp2DyMyycxCZWXYOIjPLzkFkZtk5iMwsOweRmWXnIDKz7BxEZpadg8jMsnMQmVl2DiIzy85BZGbZOYjMLDsHkZlld84gkvRNSUckPVdS9ieSXpD0rKS/kTS3ZNtGSXsk7ZZ0Q43abWZ1ZDQjonuAtWVlW4ErI+K3gBeBjQCSVgM3A29Kx/yZpMZxa62Z1aVzBlFE/APwalnZ30VEf1r9GbA0La8Dvh0RpyJiL4U/PX3tOLbXzOrQeMwRfRj4QVpeAuwv2dadys4iaYOkLkldPT0949AMM7tQVRVEkj4H9AP3ne+xEbEpIjoioqOtra2aZpjZBa5prAdKugW4Ebg+IiIVHwCWley2NJWZmQ1rTCMiSWuBTwPviYgTJZs6gZsltUhaCbQDT1TfTDOrZ+ccEUm6H7gOmC+pG7iDwrtkLcBWSQA/i4h/ExE7JT0A7KJwyfbRiBioVePNrD7oN1dV+XR0dERXV1fuZphZDUnaHhEdlbb5zmozy85BZGbZOYjMLDsHkZll5yAys+wcRGaWnYPIzLJzEJlZdg4iM8vOQWRm2TmIzCw7B5GZZecgMrPsHERmlp2DyMyycxCZWXYOIjPLzkFkZtlNiq+KldQDvA4czdiM+VO8/snQBtdf3/VfGhEV/3bYpAgiAEldw32freufGm1w/VO3fl+amVl2DiIzy24yBdEm159d7ja4/ila/6SZIzKzqWsyjYjMbIpyEJlZdpMiiCStlbRb0h5Jt09AfcskPSppl6Sdkj6eyi+StFXSS+nnvBq3o1HSDkkPp/WVkral5+E7kqbVsO65krZIekHS85LeOpH9l/TH6bl/TtL9klpr3X9J35R0RNJzJWUV+6yCr6W2PCvpmhrV/yfp3+BZSX8jaW7Jto2p/t2SbqhF/SXbPiUpJM1P6+Pe/xFFRNYH0Aj8ArgMmAY8A6yucZ2LgWvS8mzgRWA18N+A21P57cAXa9yOTwJ/BTyc1h8Abk7Lfw782xrWvRm4LS1PA+ZOVP+BJcBeYHpJv2+pdf+B3wWuAZ4rKavYZ+DdwA8AAWuAbTWq/58BTWn5iyX1r06/Cy3AyvQ70jje9afyZcAPgX3A/Fr1f8S21fLko3xy3gr8sGR9I7BxgtvwEPB7wG5gcSpbDOyuYZ1LgUeAdwIPp3/woyUvyiHPyzjXPScFgcrKJ6T/KYj2AxcBTan/N0xE/4EVZUFQsc/A/wTeX2m/8ay/bNsfAvel5SG/Byko3lqL+oEtwG8Dr5QEUU36P9xjMlyaFV+URd2pbEJIWgFcDWwDFkbEwbTpELCwhlV/Bfg0cCatXwwci4j+tF7L52El0AN8K10a3iVpJhPU/4g4APwp8EvgIPBrYDsT1/9Sw/U5x+vywxRGIRNWv6R1wIGIeKZs04T2fzIEUTaSZgEPAp+IiNdKt0Xhv4Ga3Nsg6UbgSERsr8X5R6GJwhD9GxFxNYXP+Q2Zm6tx/+cB6ygE4iXATGBtLeo6H7Xs87lI+hzQD9w3gXXOAD4L/KeJqnM4kyGIDlC4Ri1amspqSlIzhRC6LyK+m4oPS1qcti8GjtSo+rcB75H0CvBtCpdnXwXmSmpK+9TyeegGuiNiW1rfQiGYJqr/7wL2RkRPRJwGvkvhOZmo/pcars8T9rqUdAtwI/CBFIYTVf8qCv8ZPJNei0uBpyQtmqD6B02GIHoSaE/vmEwDbgY6a1mhJAF3A89HxJdKNnUC69PyegpzR+MuIjZGxNKIWEGhv38fER8AHgXeOwH1HwL2S7oiFV0P7GKC+k/hkmyNpBnp36JY/4T0v8xwfe4EPpjePVoD/LrkEm7cSFpL4RL9PRFxoqxdN0tqkbQSaAeeGM+6I+LnEbEgIlak12I3hTdxDjFB/S9tTPYHhRn6Fym8M/C5Cajv7RSG4M8CT6fHuynM0zwCvAT8CLhoAtpyHb951+wyCi+2PcBfAy01rPcqoCs9B/8bmDeR/Qc+D7wAPAfcS+HdoZr2H7ifwpzUaQq/dLcO12cKbx58Pb0mfw501Kj+PRTmYoqvwz8v2f9zqf7dwO/Xov6y7a/wm8nqce//SA9/xMPMspsMl2ZmNsU5iMwsOweRmWXnIDKz7BxEZpadg8jMsnMQmVl2/x9zo5DGQiwgBQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "random_idx = random.randint(0,train_image.__len__())\n",
    "image = cv2.imread(train_image[random_idx])\n",
    "plt.imshow(image)\n",
    "plt.title(\"Label: \" + train_label[random_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train test and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "# laoding the images from the path\n",
    "for path in train_image:    \n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (100, 100))\n",
    "    img = np.array(img)\n",
    "    X_train.append(img)\n",
    "\n",
    "for path in test_image:    \n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (100, 100))\n",
    "    img = np.array(img)     \n",
    "    X_test.append(img)\n",
    "\n",
    "# creating numpy array from the images\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (7557, 100, 100, 3)\n",
      "X_test shape:  (1010, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# label encoding the 16 symbols\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y_train_temp = label_encoder.fit_transform(train_label)\n",
    "y_test_temp = label_encoder.fit_transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape:  (7557, 16)\n",
      "y_test shape:  (1010, 16)\n"
     ]
    }
   ],
   "source": [
    "# creating matrix labels list\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train_temp, 16)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test_temp, 16)\n",
    "\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 01:32:54.702525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 01:32:54.703047: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/anton/anaconda3/envs/photomath/lib/python3.7/site-packages/cv2/../../lib64:/home/anton/ea202012001_adas_asw_sop/build/devel/lib:/opt/ros/noetic/lib\n",
      "2021-12-21 01:32:54.703141: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/anton/anaconda3/envs/photomath/lib/python3.7/site-packages/cv2/../../lib64:/home/anton/ea202012001_adas_asw_sop/build/devel/lib:/opt/ros/noetic/lib\n",
      "2021-12-21 01:32:54.703206: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/anton/anaconda3/envs/photomath/lib/python3.7/site-packages/cv2/../../lib64:/home/anton/ea202012001_adas_asw_sop/build/devel/lib:/opt/ros/noetic/lib\n",
      "2021-12-21 01:32:54.723828: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/anton/anaconda3/envs/photomath/lib/python3.7/site-packages/cv2/../../lib64:/home/anton/ea202012001_adas_asw_sop/build/devel/lib:/opt/ros/noetic/lib\n",
      "2021-12-21 01:32:54.723926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/anton/anaconda3/envs/photomath/lib/python3.7/site-packages/cv2/../../lib64:/home/anton/ea202012001_adas_asw_sop/build/devel/lib:/opt/ros/noetic/lib\n",
      "2021-12-21 01:32:54.723993: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/anton/anaconda3/envs/photomath/lib/python3.7/site-packages/cv2/../../lib64:/home/anton/ea202012001_adas_asw_sop/build/devel/lib:/opt/ros/noetic/lib\n",
      "2021-12-21 01:32:54.724005: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-21 01:32:54.724870: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 100, 100, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 98, 98, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 49, 49, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 49, 49, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 47, 47, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 23, 23, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 23, 23, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 33856)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               17334784  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                8208      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,408,560\n",
      "Trainable params: 17,408,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# using sequential model for training\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer and taking input in this of shape 100x100x3 ->  100 x 100 pixles and 3 channels\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(100, 100, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "\n",
    "# maxpooling will take highest value from a filter of 2*2 shape\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# it will prevent overfitting by making it hard for the model to idenify the images\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# last layer predicts 16 labels\n",
    "model.add(Dense(16, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# displaying the model\n",
    "import keras\n",
    "keras.utils.vis_utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ee2485aa751c599ce955f330c83e2017042ac7d4e00197592ebc9f7f9c5c897"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
